{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кривоногов Н.В., INN, практическое задание № 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте видоизменить параметры разобранной на уроке нейронной сети таким образом, чтобы улучшить её точность. Проведите анализ:\n",
    "- Что приводит к ухудшению точности нейронной сети?\n",
    "- Что приводит к увеличению её точности?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ1zS4kdPzj7"
   },
   "source": [
    "#### Двухслойная нейронная сеть на numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "cuOixqmrPzj7",
    "outputId": "c014f815-663f-4c6e-d607-daa81877f80d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\lib\\site-packages\\seaborn\\axisgrid.py:1242: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нейронной сети 97.83%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Построение двухслойной нейронный сети для классификации цветков ириса\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# sklearn здесь только, чтобы разделить выборку на тренировочную и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "### Шаг 1. Определение функций, которые понадобяться для обучения\n",
    "\n",
    "# преобразование массива в бинарный вид результатов\n",
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "# преобразование массива в необходимый вид\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "# сигмоида и ее производная\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# нормализация массива\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "### Шаг 2. Подготовка тренировочных данных\n",
    "\n",
    "# получения данных из csv файла. укажите здесь путь к файлу Iris.csv\n",
    "iris_data = pd.read_csv(\"./Iris.csv\")\n",
    "# print(iris_data.head()) # расскоментируйте, чтобы посмотреть структуру данных\n",
    "\n",
    "# репрезентация данных в виде графиков\n",
    "g = sns.pairplot(iris_data.drop(\"Id\", axis=1), hue=\"Species\")\n",
    "# plt.show() # расскоментируйте, чтобы посмотреть\n",
    "\n",
    "# замена текстовых значений на цифровые\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# формирование входных данных\n",
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.values)\n",
    "\n",
    "# формирование выходных данных(результатов)\n",
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.values\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "   \n",
    "    \n",
    "### Шаг 3. Обученние нейронной сети\n",
    "\n",
    "# число нейронов скрытого слоя\n",
    "neuron_numb = 3\n",
    "\n",
    "# присваивание случайных весов\n",
    "w0 = 2*np.random.random((4, neuron_numb)) - 1 # для входного слоя   - 4 входа, neuron_numb выхода\n",
    "w1 = 2*np.random.random((neuron_numb, 3)) - 1 # для внутреннего слоя - neuron_numb входов, 3 выхода\n",
    "\n",
    "# скорость обучения (learning rate)\n",
    "n = 0.01 # 0.001\n",
    "\n",
    "# массив для ошибок, чтобы потом построить график\n",
    "errors = []\n",
    "\n",
    "# процесс обучения\n",
    "for i in range(100000): # 100,000\n",
    "\n",
    "    # прямое распространение(feed forward)\n",
    "    layer0 = X_train\n",
    "    layer1 = sigmoid(np.dot(layer0, w0))\n",
    "    layer2 = sigmoid(np.dot(layer1, w1))\n",
    "\n",
    "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
    "    layer2_error = y_train - layer2\n",
    "    layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "    \n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "    \n",
    "    w1 += layer1.T.dot(layer2_delta) * n\n",
    "    w0 += layer0.T.dot(layer1_delta) * n\n",
    "    \n",
    "    error = np.mean(np.abs(layer2_error))\n",
    "    errors.append(error)\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "### Шаг 4. Демонстрация полученных результатов\n",
    "# черчение диаграммы точности в зависимости от обучения\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Обучение')\n",
    "plt.ylabel('Ошибка')\n",
    "# plt.show() # раскоментируйте, чтобы посмотреть \n",
    "        \n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1)\n",
    "- Количество итераций 10.000 - точность 75.8%.\n",
    "- Количество итераций 100.000 - точность 93.61%. \n",
    "- Количество итераций 500.000 - точность 97.42%.\n",
    "- Количество итераций 1.000.000 - точность 98.16%.\n",
    "\n",
    "При возрастании количества итераций (эпох) (for i in range) точность нейронной сети возрастает. И наоборот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2)\n",
    "- Скорость обучения 0.0001 - точность 77.74%.\n",
    "- Скорость обучения 0.001 - точность 93.61%. \n",
    "- Скорость обучения 0.01 - точность 96.96%. \n",
    "- Скорость обучения 0.1 - точность 96.36%. \n",
    "- Скорость обучения 1 - точность 54.5%. \n",
    "\n",
    "Точность нейронной сети имеет нелинейную (выпуклую вверх) зависимость от скорости её обучения (n). Так, при возрастании learning rate до 0.01 точность растет, а при дальнейшем росте learning rate точность нейронной сети падает. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3)\n",
    "- Число нейронов скрытого слоя 2 - точность 77.42%.\n",
    "- Число нейронов скрытого слоя 3 - точность 97.83%. \n",
    "- Число нейронов скрытого слоя 4 - точность 96.65%. \n",
    "- Число нейронов скрытого слоя 5 - точность 96.37%. \n",
    "- Число нейронов скрытого слоя 6 - точность 97.58%. \n",
    "- Число нейронов скрытого слоя 7 - точность 97.72%.\n",
    "- Число нейронов скрытого слоя 8 - точность 99.19%.\n",
    "- Число нейронов скрытого слоя 9 - точность 98.04%.\n",
    "- Число нейронов скрытого слоя 10 - точность 96.84%.\n",
    "\n",
    "Точность нейронной сети имеет нелинейную зависимость от числа нейронов скрытого слоя (neuron_numb). Так, при возрастании числа до 3 точность растет, дальше падает, при числе нейронов от 6 - начинается рост, далее максимум точности при числе нейронов скрытого слоя 8, а дальше снова падение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность нейронной сети имеет хорошие показатели при следующих параметрах: \n",
    "- Количество итераций 1.000.000\n",
    "- Скорость обучения 0.01\n",
    "- Число нейронов скрытого слоя 8. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
