{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кривоногов Н.В., INN, практическое задание № 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем набор примеров fashion-MNIST\n",
    "1. Опишите - какой результат нейросети получен в зависимости от:\n",
    "  - числа нейронов в слое (для 2-х слойной сети), \n",
    "  - числа слоев (2, 3, 5, 10) при близких размерах сети (близкое число тренируемых параметров).\n",
    "  - фиксируйте для тренировочного и тестового набора метрики accuracy.\n",
    "2.  Проверьте работу разных оптимизаторов (SGD, Adam, RMSProp) для одной из моделей п.1. Фиксируйте для тренировочного и тестового набора метрики accuracy.\n",
    "\n",
    "3. Сделайте вывод - что помогло вам улучшить качество классификации в нейросети на тестовом наборе? \n",
    "\n",
    "4. Для одного варианта сети сформируйте матрицу ошибок по классам. Оцените качество модели по каждому классу отдельно (полнота, точность)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train_labels), (X_test, y_test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормировка\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытягивание признаков\n",
    "X_train = X_train.reshape((-1, 28 * 28))\n",
    "X_test = X_test.reshape((-1, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense       # Полносвязный линейный слой\n",
    "from keras.models import Sequential  # Класс последовательности слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons_1 = 64 # 32, 16, 8\n",
    "num_neurons_2 = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_neurons_1, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(num_neurons_2, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример на лекции показал, что лучшим оптимизатором является Adam: \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train_labels)\n",
    "y_test = to_categorical(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# передача обучающего датасета keras модели\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Число нейронов в слое (для 2-х слойной сети) = 64 и 10, метрики на train = 0.8786, на test = 0.8626.\n",
    "\n",
    "- Число нейронов в слое (для 2-х слойной сети) = 32 и 10, метрики на train = 0.8690, на test = 0.8552.\n",
    "\n",
    "- Число нейронов в слое (для 2-х слойной сети) = 16 и 10, метрики на train = 0.8625, на test = 0.8491.\n",
    "\n",
    "- Число нейронов в слое (для 2-х слойной сети) = 8 и 10, метрики на train = 0.8440, на test = 0.8305.\n",
    "\n",
    "Вывод 1: при увеличении количества нейронов в слое метрика возрастает (и наоборот соответственно). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "# model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "# model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "# model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "# model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "# model.add(Dense(16, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Число слоев = 2, метрики на train = 0.8613, на test = 0.8466.\n",
    "\n",
    "- Число слоев = 3, метрики на train = 0.8629, на test = 0.8572.\n",
    "\n",
    "- Число слоев = 5, метрики на train = 0.8560, на test = 0.8461.\n",
    "\n",
    "- Число слоев = 10, метрики на train = 0.8503, на test = 0.8365.\n",
    "\n",
    "Вывод 2: зависимость метрики от числа слоев имеет нелинейный характер. Так в данном примере метрика максимальна при числе слоев, равном трем. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# буду сохранять модели в словарь:\n",
    "models = {}\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "colors = ['g', 'b', 'r', 'y']\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "\n",
    "# вектор для вывода результатов:\n",
    "epoch = np.arange(num_epochs+1)\n",
    "\n",
    "# буду изменять оптимизаторы:\n",
    "for i, i_optim in enumerate([keras.optimizers.SGD(),\n",
    "                             keras.optimizers.Adam(),\n",
    "                             keras.optimizers.RMSprop()]):\n",
    "    \n",
    "    # создаю рабочую модель model_i, куда буду загружать эти веса (она должна быть идентичной структуры):\n",
    "    num_neurons_1 = 64\n",
    "    num_neurons_2 = 10\n",
    "\n",
    "    model_i = Sequential()\n",
    "    model_i.add(Dense(num_neurons_1, input_shape=(28 * 28,), activation='relu'))\n",
    "    model_i.add(Dense(num_neurons_2, activation='sigmoid'))\n",
    "    \n",
    "    # компилирую model_i с одним из оптимизаторов:\n",
    "    model_i.compile(\n",
    "        optimizer=i_optim,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        )\n",
    "    \n",
    "    # вычисляю ошибку для model_i без обучения:\n",
    "    h0_train = model_i.evaluate(X_train, y_train, verbose=0)\n",
    "    h0_val = model_i.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # провожу обучение модели:\n",
    "    h = model_i.fit(X_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)\n",
    "    \n",
    "    # записываю обученную модель в словарь:\n",
    "    models[i_optim.get_config()['name']] = model_i\n",
    "\n",
    "    # строю графики:\n",
    "    plt.plot(epoch, np.log([h0_train[0]] + h.history['loss']),\n",
    "             '-', c=colors[i],\n",
    "             label=model_i.optimizer.get_config()['name'] + ' train')\n",
    "    plt.plot(epoch, np.log([h0_val[0]] + h.history['val_loss']),\n",
    "             '--', c=colors[i],\n",
    "             label=model_i.optimizer.get_config()['name'] + ' val')\n",
    "    print('=' * 20)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('нейросети от оптимизатора log(loss)')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('log(loss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Оптимизатор SGD, метрики на train = 0.8446, на test = 0.8352.\n",
    "\n",
    "- Оптимизатор Adam, метрики на train = 0.8810, на test = 0.8576.\n",
    "\n",
    "- Оптимизатор RMSProp, метрики на train = 0.8802, на test = 0.8511.\n",
    "\n",
    "Вывод 3: оптимизатор Adam - лучший, как на train, так и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод 4: качество классификации в нейросети на тестовом наборе помогает улучшить подбор её оптимальных параметров, таких как: количество нейронов в слое, количество слоев, оптимизатор. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.5438 - accuracy: 0.8104 - val_loss: 0.4495 - val_accuracy: 0.8422\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4013 - accuracy: 0.8561 - val_loss: 0.4119 - val_accuracy: 0.8544\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3632 - accuracy: 0.8676 - val_loss: 0.4002 - val_accuracy: 0.8539\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3422 - accuracy: 0.8760 - val_loss: 0.4185 - val_accuracy: 0.8437\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(32, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[880   1  18  22   1   0  61   0  17   0]\n",
      " [  7 959   2  27   2   0   1   0   2   0]\n",
      " [ 15   1 905  11  25   0  37   0   6   0]\n",
      " [ 48   7  13 889  21   0  18   0   4   0]\n",
      " [  1   0 411  50 466   0  69   0   3   0]\n",
      " [  0   0   0   1   0 938   0  35   2  24]\n",
      " [195   1 193  26  37   1 531   0  16   0]\n",
      " [  0   0   0   0   0  25   0 937   0  38]\n",
      " [  6   1   6   5   0   2   4   3 973   0]\n",
      " [  0   0   0   0   0   4   1  36   0 959]]\n"
     ]
    }
   ],
   "source": [
    "# формирую матрицу ошибок по классам:\n",
    "\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      1000\n",
      "           1       0.99      0.96      0.97      1000\n",
      "           2       0.58      0.91      0.71      1000\n",
      "           3       0.86      0.89      0.88      1000\n",
      "           4       0.84      0.47      0.60      1000\n",
      "           5       0.97      0.94      0.95      1000\n",
      "           6       0.74      0.53      0.62      1000\n",
      "           7       0.93      0.94      0.93      1000\n",
      "           8       0.95      0.97      0.96      1000\n",
      "           9       0.94      0.96      0.95      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.86      0.84      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# качество модели по каждому классу отдельно (полнота, точность):\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод 5: для класса \"1\" точность максимальна, для класса \"6\" точность минимальна; для класса \"8\" полнота максимальна, для класса \"4\" полнота минимальна. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
